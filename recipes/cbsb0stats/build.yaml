name: cbsb0stats
version: 1.1.0
icon: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAADsUlEQVRIS7WVbUjTWxzHv2erucc2VwaVvfCSuOl6cDW7BVsQinjBAs0SSzMiwZDswWp3XXsA71WsXgWhpZCvBMkwiN5UEA1rg0atpVOiKGfTclulW2mudXfO2j/nJAj1wJ/B2f///fwevud3yOZzge/hBbro7/Rntvtk01k/U58L8R9CMVoMMF/iVJf8eWYsDvC7Gc0UOQs6LEQ2nh6NAUwV/zb5BcHPH0AEUvAFkhnL+Cvx8AcgWbWfOAAVD4VC8Lss8D5rh9z/ECqVCjabDcEV+ZD9kYPX13cxQ0xdiZkHIFqug3ilAWSBkEVOxVmJdP985FwUCn3DsOUSMsWP0dHRAbFYzOnY7XZs1m/F5zEfC4IQwv0XDAZhNpuxveI8lmz5F3xhIpct2XDqA+eiMZcVsFajr68PPT09yMvLg8fjQVlZGZqamtDd3Q29Xs8Azc3NqK+vh1QqRW1tLYqLi1FZWYkbL1ZBllYQC4i66NWNcnRePgyDwQC5XA4kasJlycY783+oq6uDTqdDbm4uAzQ0NMBkMrEsNBoNHA4HjEYjmu+MQrmx5idgvcnHSkQbar+QjIGBAUxMTCA1NRXqgz3gi5Tw2K5i+P5priQU4HQ6YbFYIJPJkJ2dDYlEgqSkJAi0JshUOyIA6iLt314GmAyM4PklNbxeL1wuF3T6v5BWYWMvjr68A9fNvTEAGoTf7wePx4NCoWBZ5efn4/EXA6SqIq7RJNPoiWQQnIDjYjJ6e3uRkpICkUiE9Oo3AG8BvE+vYYP4IUpLS1mtp5dIKBSyoOij1Wqxcr8DPH5CxEXrTo5wLnpz6yCunN2JoqIiZGRkwLesFMIkDQZvVcD55AGoW9RqdRyApma1WllZlUolVuw2gy9eGgGsPfGec9Hoq3sIPKiG2+2Gz+dDYWEh+vv70djYiPLycpSUlKC9vZ0BOjs70dLSAoFAgKqqKuTk5KCrqwsFBQVI3mcHiWZAAVEXhYJf4bpdhW1Zi9Da2so+jq62tjYGiR7G6eeAHkbabEGmEZK0H02mGaw5/i5mVIz7XmLo7kmMuy2snrSB9BDRpio3nYDvUWPcSY5uKLJqIEnfw0XPXLS6Zjh22NFx8TWAwKAFk/4hhMLN54sWQ7BYBX6CHOMjzrBDwp9G747w+7yFEpAEBfjSZMaKWpTNIs2xoZ+AKTMkZoTPYp9kHHVHALMQ+VUwJP3I28iFOcN1ORf7EcA8ibNzoD48GA+Yw4yIqtoV56K5LBdJOzQwry76H0tMj7XJU3hkAAAAAElFTkSuQmCC
architectures:
  - x86_64
readme: |-
  ----------------------------------
  ## cbsb0stats/{{ context.version }} ##
  This open recon tool will compute a b0 map based on two magnitude images 
  and one phasediff image from a gradien echo field mapping sequence.

  # WARNING: This is an early version and as of this version no testing
  # has been performed in a working environment (in a MRI as a Openrecon package).

  you can setup the builder environment with:
  ```bash
  python3 -m venv env
  source env/bin/activate
  pip install -e .
  ```

  you can build this recipe with:
  ```bash
  source env/bin/activate
  ./builder/build.py generate testing --recreate --build --login --architecture x86_64
  ```

  or shorter: open the build.yaml file in the local terminal and run:
  ```
  sf-login 
  ```

  ## Commands for testing
        
        # Convert input DICOMs to ISMRMRD format
    python /opt/code/python-ismrmrd-server/dicom2mrd.py \
      -o /buildhostdirectory/output.h5 \
      /buildhostdirectory/dicoms

    # Start OpenRecon server
    python3 /opt/code/python-ismrmrd-server/main.py -v -r -H=0.0.0.0 -p=9002 -s -S=/buildhostdirectory/tmp/saved_data/ -l=/buildhostdirectory/tmp/log_data/ &
    sleep 5

    
    python3 /opt/code/python-ismrmrd-server/client.py \
      -G dataset \
      -o /buildhostdirectory/output.h5 \
      /buil1hostdirectory/input.h5 \
      -c  cbsb0stats

    # Check output h5 data in "H5Web" VS code plugin viewer
  ----------------------------------
build:
  kind: neurodocker
  base-image: ubuntu:22.04
  pkg-manager: apt
  directives:
    - file:
        name: cbsb0stats.py
        contents: |-
          import ismrmrd
          import os
          import logging
          import traceback
          import numpy as np
          import xml.dom.minidom
          import base64
          import mrdhelper
          import constants
          import nibabel as nib
          import subprocess
          import ast
          import json
          import torch

          # WARNING: This is an early version and as of this version no testing
          # has been performed in a working environment (in a MRI as a Openrecon package).


          # Folder for debug output files
          debugFolder = "/tmp/share/debug"

          isB0CollectionComplete = False
          isB0PhaseCollected = False
          isB0TEsCollected = False

          # These variables are for dicom2mrd.py testing. 
          CONFIG_IS_TESTING = False
          CONFIG_BITSSTORED = 12
          CONFIG_RESCALESLOPE = 2
          CONFIG_RESCALEINTERCEPT = -4096


          def explore(obj, depth=0, max_depth=3):
              #name = getattr(obj, "__name__", type(obj).__name__)
              #logging.info(f"CBS_EXPLORER: Target -{name}")
              indent = "  " * depth
              if depth > max_depth:
                  return
              for attr in dir(obj):
                  if attr.startswith("_"):
                      continue
                  try:
                      val = getattr(obj, attr)
                  except Exception:
                      continue
                  logging.info(f"CBS_EXPLORER: {indent}{attr}: {type(val).__name__}")
                  if not isinstance(val, (int, float, str, bool, bytes, list, tuple, dict)):
                      explore(val, depth + 1, max_depth)

          def findTE(meta,metadata=None):
              logging.debug(f"CBS_DEBUG: looking for TE...")
              if (metadata is not None):
                  logging.debug(f"CBS_DEBUG: looking for TE...  - searching metadata...")
                  if (mrdhelper.get_userParameterDouble_value(metadata, 'EchoTime') is not None):
                      logging.debug(f"CBS_DEBUG: looking for TE...  - found result for TE via mrdhelper.get_userParameterDouble_value: {mrdhelper.get_userParameterDouble_value(metadata, 'EchoTime')}")
                      return str(mrdhelper.get_userParameterDouble_value(metadata, 'EchoTime'))
                  else:
                      logging.debug(f"CBS_DEBUG: looking for TE...  - mrdhelper.get_userParameter for TE is empty, moving to next method")
                  if metadata.sequenceParameters.TE:
                      logging.debug(f"CBS_DEBUG: looking for TE...  - metadata.sequenceParameters is: {metadata.sequenceParameters.TE}")
                      if isinstance(collapseIfSoleyUnique(metadata.sequenceParameters.TE),float):
                          logging.debug(f"CBS_DEBUG: suitable TE found...  - metadata.sequenceParameters is unique using TE from metadata.sequenceParmeters.TE")
                          return str(collapseIfSoleyUnique(metadata.sequenceParameters.TE))
                      else:
                          logging.debug(f"CBS_DEBUG: looking for TE...  - metadata.sequenceParameters is not unique, moving to next method")
                  else: logging.debug(f"CBS_DEBUG: looking for TE...  - metadata.sequenceParameters is empty, moving to next method")       
              else: logging.debug(f"CBS_DEBUG: looking for TE... - metadata was not provided or was not found, moving to next method")
              if isDicomJsonData(meta):
                  logging.debug(f"CBS_DEBUG: looking for TE... - DicomJson was found extracting TEs")
                  TE = [getAcquisitionData(m, "te") for m in meta]
                  if all(te is None for te in TE):
                      logging.debug(f"CBS_DEBUG: looking for TE... - DicomJson does not contain TEs")
                  elif isinstance(collapseIfSoleyUnique(TE),list):
                      logging.debug(f"CBS_DEBUG: looking for TE... - TEs extracted but not soley unique logging result and defaulting to config TE Values.\n{collapseIfSoleyUnique(TE)}")
                  elif isinstance(collapseIfSoleyUnique(TE),float):
                      logging.debug(f"CBS_DEBUG: looking for TE... - Successfully extracted TEs and they are all the same.")
                      return str(collapseIfSoleyUnique(TE))
                  else:
                      logging.debug(f"CBS_DEBUG: looking for TE... - Cannot extract TEs via DicomJson")
              logging.warning(f"CBS_WARNING: looking for TE... - Cannot find TE default to config TE Values.")
              TE_Default = str("TE Not found")
              return TE_Default


          def isDicomJsonData(meta):
              if not meta: 
                  logging.warning("CBS_WARNING: failed to parse meta, meta may be empty.")
                  return False
              meta = meta[0]
              py_dict = ast.literal_eval(str(meta))
              if "DicomJson" not in py_dict:
                  return False
              else:
                  return True

          def LogDicomJsonData(meta):
              if not meta: 
                  logging.warning("CBS_WARNING: failed to parse meta, meta may be empty.")
                  return False
              try:
                  meta = meta[0]
                  py_dict = ast.literal_eval(str(meta))
                  if not isDicomJsonData(meta):
                      logging.debug("CBS_DEBUG: - No DicomJson key found in meta.")
                      return None
                  decoded64_utf8 = base64.b64decode("".join(py_dict["DicomJson"].split())).decode("utf-8")
                  dicom_json = json.loads(decoded64_utf8)
                  logging.debug(
                      "CBS_DEBUG: - DicomJson Detected:\n" +
                      json.dumps(dicom_json, indent=4, sort_keys=True)
                  )
                  return dicom_json
              except (ValueError, SyntaxError, KeyError, json.JSONDecodeError, base64.binascii.Error) as e:
                  logging.error(f"CBS_ERROR: - Failed to parse DicomJson: {e}")
                  return None

          def GPUEnvironmentLog():
              # GPU Environment Testing
              logging.debug(f"CBS_LOG: CUDA Environment Variables:")
              logging.debug(f"CBS_LOG: torch.cuda.is_available: {torch.cuda.is_available()}")
              if (torch.cuda.is_available()):
                  logging.debug(f"CBS_LOG: torch.cuda.device_count: {torch.cuda.device_count()}")
                  logging.debug(f"CBS_LOG: torch.cuda.current_device: {torch.cuda.current_device()}")
                  logging.debug(f"CBS_LOG: torch.cuda.device: {torch.cuda.device(torch.cuda.current_device())}")
                  logging.debug(f"CBS_LOG: torch.cuda.get_device_name: {torch.cuda.get_device_name(torch.cuda.current_device())}")
              return None


           ### ---- Here for new functions
          def getDiagnosticInfo(images,data,head,meta,metadata,B0map_Dict):
              LogDicomJsonData(meta)
              # Diagnostic info
              matrix    = np.array(head[0].matrix_size  [:])
              fov       = np.array(head[0].field_of_view[:])
              voxelsize = fov/matrix
              read_dir  = np.array(images[0].read_dir )
              phase_dir = np.array(images[0].phase_dir)
              slice_dir = np.array(images[0].slice_dir)
              logging.info(f'CBS_LOG: MRD computed matrix [x y z] : {matrix   }')
              logging.info(f'CBS_LOG: MRD computed fov     [x y z] : {fov      }')
              logging.info(f'CBS_LOG: MRD computed voxel   [x y z] : {voxelsize}')
              logging.info(f'CBS_LOG: MRD read_dir         [x y z] : {read_dir }')
              logging.info(f'CBS_LOG: MRD phase_dir        [x y z] : {phase_dir}')
              logging.info(f'CBS_LOG: MRD slice_dir        [x y z] : {slice_dir}')
              logging.debug(f"CBS_DEBUG: All Head Info for first slice: {head[0]}")
              logging.debug(f"CBS_DEBUG: All Meta Info for first slice: {meta[0]}")
              logging.info("CBS_LOG: %d Echo Time's found: %s" ,len(B0map_Dict),(list(B0map_Dict)))
              logging.debug("CBS_DEBUG: Original image data before transposing is %s" % (data.shape,))
              if (ismrmrd.Meta.serialize(meta[0]) is not None):
                  logging.debug(f"CBS_LOG: First meta header - \n {ismrmrd.Meta.serialize(meta[0])}")
              if 'IceMiniHead' in meta[0]:
                  logging.debug("CBS_LOG: IceMiniHeader detected, first IceMiniHeader is: %s", base64.b64decode(meta[0]['IceMiniHead']).decode('utf-8'))
              logging.debug("CBS_LOG: Attempting get_userParameterXXX_value collection: ")
              if (mrdhelper.get_userParameterLong_value(metadata, 'BitsStored') is not None):
                  logging.debug(f"CBS_LOG: BitsStored value of {mrdhelper.get_userParameterLong_value(metadata, 'BitsStored')} found via mrdhelper.getuserParam.")
              if (mrdhelper.get_userParameterDouble_value(metadata, 'RescaleIntercept') is not None):
                  logging.debug(f"CBS_LOG: RescaleIntercept value of {mrdhelper.get_userParameterDouble_value(metadata, 'RescaleIntercept')} found via mrdhelper.getuserParam.")
              if (mrdhelper.get_userParameterLong_value(metadata, 'RescaleSlope') is not None):
                  logging.debug(f"CBS_LOG: RescaleSlope value of {mrdhelper.get_userParameterLong_value(metadata, 'RescaleSlope')} found via mrdhelper.getuserParam.")
              if (mrdhelper.get_userParameterDouble_value(metadata, 'EchoTime') is not None):
                  logging.debug(f"CBS_LOG: EchoTime value of {mrdhelper.get_userParameterDouble_value(metadata, 'EchoTime')} found via mrdhelper.getuserParam.")
              if (mrdhelper.get_userParameterLong_value(metadata, 'InstanceNumber') is not None):
                  logging.debug(f"CBS_LOG: InstanceNumber value of {mrdhelper.get_userParameterLong_value(metadata, 'InstanceNumber')} found via mrdhelper.getuserParam.")
              return None

          def imageOutPreparation_basic(data,head,meta,currentSeries):
              imagesOut = [None] * data.shape[-1]
              for iImg in range(data.shape[-1]):
                  # Create new MRD instance for the final image
                  # Transpose from convenience shape of [y x z cha] to MRD Image shape of [cha z y x]
                  # from_array() should be called with 'transpose=False' to avoid warnings, and when called
                  # with this option, can take input as: [cha z y x], [z y x], or [y x]
                  imagesOut[iImg] = ismrmrd.Image.from_array(data[...,iImg].transpose((3, 2, 0, 1)), transpose=False)

                  # Create a copy of the original fixed header and update the data_type
                  oldHeader = head[iImg]
                  oldHeader.data_type = imagesOut[iImg].data_type

                  # Increment series number when flag detected (i.e. follow ICE logic for splitting series)
                  if mrdhelper.get_meta_value(meta[iImg], 'IceMiniHead') is not None:
                      if mrdhelper.extract_minihead_bool_param(base64.b64decode(meta[iImg]['IceMiniHead']).decode('utf-8'), 'BIsSeriesEnd') is True:
                          currentSeries += 1

                  imagesOut[iImg].setHead(oldHeader)      #Same

                  # Create a copy of the original ISMRMRD Meta attributes and update
                  tmpMeta = meta[iImg]
                  tmpMeta['DataRole']                       = 'Image'
                  tmpMeta['ImageProcessingHistory']         = ['PYTHON', 'B0MAP']
                  tmpMeta['SequenceDescriptionAdditional']  = 'OpenRecon_cbsb0stats'
                  tmpMeta['Keep_image_geometry']            = 1

                  # Add image orientation directions to MetaAttributes if not already present
                  if tmpMeta.get('ImageRowDir') is None:
                      tmpMeta['ImageRowDir'] = ["{:.18f}".format(oldHeader.read_dir[0]), "{:.18f}".format(oldHeader.read_dir[1]), "{:.18f}".format(oldHeader.read_dir[2])]

                  if tmpMeta.get('ImageColumnDir') is None:
                      tmpMeta['ImageColumnDir'] = ["{:.18f}".format(oldHeader.phase_dir[0]), "{:.18f}".format(oldHeader.phase_dir[1]), "{:.18f}".format(oldHeader.phase_dir[2])]

                  metaXml = tmpMeta.serialize()
                  #logging.debug("CBS_DEBUG: Image data has %d elements", imagesOut[iImg].data.size)

                  imagesOut[iImg].attribute_string = metaXml
              return imagesOut

          # Returns a float if all elements in a lst are identical, else returns the lst
          def collapseIfSoleyUnique(lst):
              return float(lst[0]) if lst and len(set(lst)) == 1 and lst[0] is not None else lst

          # Finds Dicom Standard Dictionary parameters, only does TE right now,
          # pretty sure this can be done with ismrmrd.Meta.deserialize(img.attribute_string)
          # but not sure how.

          def getAcquisitionData(meta, Parameter):
              tag_keys = {"Echo Time": "00180081",
                          "Rescale Slope":"00281053", 
                          "Rescale Intercept":"00281052", 
                          "Instance Number":"00200013"}
              
              #logging.info(f"CBS_LOG: In getAcquisitonData Meta is classified as type: {type(meta)} \n")
              if meta is None or not isinstance(meta, ismrmrd.meta.Meta):
                  logging.error("CBS_Error: Must include meta data of type: <class 'ismrmrd.meta.Meta'>")
                  return None
              Parameter = str(Parameter).replace(" ","").lower()
              if Parameter == "te" or Parameter == "echotime":
                  tag_key = tag_keys["Echo Time"] # Comes from Dicom Standard Dictionary
              elif Parameter == "ri" or Parameter == "rescaleintercept":
                  tag_key = tag_keys["Rescale Intercept"] # Comes from Dicom Standard Dictionary
              elif Parameter == "rs" or Parameter == "rescaleslope":
                  tag_key = tag_keys["Rescale Slope"] # Comes from Dicom Standard Dictionary
              elif Parameter == "in" or Parameter == "instancenumber":
                  tag_key = tag_keys["Instance Number"] # Comes from Dicom Standard Dictionary
              else:
                  logging.error("CBS_Error: Unrecognised parameter")
                  return None

              if isinstance(meta, dict):
                  # meta is already a dictionary (from getInstanceNumber)
                  py_dict = meta
              else:
                  # meta is a string representation (from other calls)
                  try:
                      py_dict = ast.literal_eval(str(meta))
                  except:
                      logging.error("CBS_ERROR: Failed to parse meta as dictionary")
                      return None

              if "DicomJson" not in py_dict:
                  logging.warning("CBS_WARNING: No DicomJson in meta, cannot extract parameter.")
                  return None
              
              try:
                  if isinstance(py_dict["DicomJson"], str):
                      # String case - remove whitespace and decode
                      dicom_json_str = "".join(py_dict["DicomJson"].split())
                      decoded64_utf8 = base64.b64decode(dicom_json_str).decode("utf-8")
                  else:
                      # Already processed case or other format
                      logging.error("CBS_ERROR: DicomJson is not a string")
                      return None
                      
                  dicom_json = json.loads(decoded64_utf8)
                  
                  if tag_key in dicom_json and "Value" in dicom_json[tag_key]:
                      value = dicom_json[tag_key]["Value"]
                      value = value[0] if isinstance(value, list) and len(value) > 0 else value
                      return value
                  else:
                      logging.error(f"CBS_ERROR: {tag_key} not found or has no 'Value'")
                      return None
              except (ValueError, SyntaxError, KeyError, json.JSONDecodeError, base64.binascii.Error) as e:
                  logging.error(f"CBS_ERROR: - Failed to parse DicomJson: {e}")
                  return None

          # Wanted to use getAcquisitionData before I define meta so use this linker function.
          def getInstanceNumber(img):
              meta = ismrmrd.Meta.deserialize(img.attribute_string)
              instance_number = getAcquisitionData(meta, "Instance Number")
              if instance_number is None:
                  logging.warning("CBS_Warning: Image has no Instance Number, using 0")
                  return 0
              return int(instance_number)

          # Unpacks big dictionary
          # doesn't deal with errors but you have bigger problems if your
          # image data has no data, head or metadata
          def UnpackInto(NewDict,ImageList):
              # data unpacks to [img cha z y x]
              NewDict["data"] = np.stack([img.data                              for img in ImageList])
              NewDict["head"] = [img.getHead()                                  for img in ImageList]
              NewDict["meta"] = [ismrmrd.Meta.deserialize(img.attribute_string) for img in ImageList]
              return NewDict

          # Does some essential reindexing and also calculates delTE
          # does not deal with errors
          def OrderDict_delTE(Dict,config):
              if all(Dict[k] == "TE Not found"for k in Dict.keys()if isinstance(k, str)):
                  TE1, TE2 = mrdhelper.get_json_config_param(config, 'TE1', default=10.0, type='float'), mrdhelper.get_json_config_param(config, 'TE2', default=12.46, type='float')
              else:
                  Numbers = [float(k) for k in Dict.keys()]
                  TE1, TE2 = min(Numbers), max(Numbers)
              NewDict = {
                  "TE1": Dict[str(TE1)],
                  "TE2": Dict[str(TE2)]
              }
              return NewDict, TE2, TE1

          def b0mapProcess(B0map_Dict,currentSeries,config):
              logging.info("CBS_LOG: Beginning B0map processing...")
              Phase = {}
              Phase = UnpackInto(Phase,B0map_Dict["phase"])
              B0map_Dict.pop("phase",None)
              B0map_Dict, te2, te1 = OrderDict_delTE(B0map_Dict,config)
              delTE = te2 - te1
              TE1,TE2 = {},{}
              TE1,TE2 = UnpackInto(TE1,B0map_Dict["TE1"]),UnpackInto(TE2,B0map_Dict["TE2"])
              B0mapImageSeriesIndex = max(TE1["head"][0].image_series_index,TE2["head"][0].image_series_index,Phase["head"][0].image_series_index) + 1
              del TE2, te2,te1
              ## Making FrequencyMap 
              
              # Formatting Phasedata
              # Extract image data into a 5D array of size [img cha z y x]
              # -- 2: Reformat to [y,x,z,cha,img]
              Phasedata = Phase["data"].transpose((3, 4, 2, 1, 0))
              Phasedata = Phasedata[:,:,0,0,:].astype(np.float64).transpose(1,0,2)
              if CONFIG_IS_TESTING:
                  Phasedata = Phasedata*CONFIG_RESCALESLOPE + CONFIG_RESCALEINTERCEPT
              xform = np.eye(4)
              nib.save(nib.nifti1.Nifti1Image(Phasedata, xform), 'temp_phase.nii')
              Phasedata = nib.load('temp_phase.nii').get_fdata()
              Phasedata = Phasedata[:, :, :, None, None]
              # Reformat to [y x img cha z] from nifti
              Phasedata = Phasedata.transpose((1, 0, 3, 4, 2)) # then try (1,0,4,3,2)
              ### Math Operations Here
              #Freqdata has array [x, y, char, img, z]
              Freqdata = (Phasedata) / (2*4096 * delTE * 1e-3)
                  # Currently data*2 - 4096 is the conversion from the input.h5 values (which are not the true values)
                  # The true values can be calculated dynamically with dicom metadata entries
                  # Rescale Intercept (0028,1052) and Rescale Slope (0028,1053)
                  # for a true value equation of: true_value = value*rescale_slope - rescale_intercept
              ###
              ## Making BrainMask, reformat to [y,x,z,cha,img]
              TE1data = TE1["data"].transpose((3, 4, 2, 1, 0))[:,:,0,0,:].astype(np.float64)
              TE1data = TE1data.transpose(1,0,2)
              if CONFIG_IS_TESTING:
                  TE1data = (TE1data*CONFIG_RESCALESLOPE + CONFIG_RESCALEINTERCEPT)
              nib.save(nib.nifti1.Nifti1Image(TE1data, xform), 'temp_te1.nii')
              if not os.path.exists('temp_te1.nii'):
                  logging.error("CBS_ERROR: temp_te1.nii not found")
              logging.info("CBS_LOG: temp_te1.nii found proceeding...")
              subprocess.run(["bet2", "temp_te1.nii", "temp_joj", "-m","-n", "-f","0.4"], check=True) # create brain mask
              subprocess.run(["fslmaths","-n.nii.gz","-dilM","-dilM","-ero","-ero","-ero","bmask_dil2_ero3"], check=True) # 2*dilate 3*erode the brain mask

              if not os.path.exists("bmask_dil2_ero3.nii.gz"):
                  logging.error("CBS_ERROR: Brain Mask not found!")

              logging.info("CBS_LOG: Brain Mask success!, proceeding with math operations...")
              BrainMask_load = nib.load("bmask_dil2_ero3.nii.gz")
              #.get_fdata() gets array [x, y, z]
              BrainMask = BrainMask_load.get_fdata()
              BrainMask = BrainMask[:, :, :, None, None]
              BrainMask = BrainMask.transpose((1, 0, 3, 4, 2))
              #now array [x, y, char, img, z] same as freqdata
              logging.info(f"CBS_LOG: BrainMask shape: {BrainMask.shape}")
              logging.info(f"CBS_LOG: Freqdata shape before processing: {Freqdata.shape}")
              if BrainMask.shape != Freqdata.shape:
                  logging.error(f"CBS_CRITICAL_ERROR: Shape mismatch - BrainMask {BrainMask.shape}, Freqdata {Freqdata.shape}")
              B0Mask = (BrainMask * Freqdata).astype(np.float64)
              logging.info(f"CBS_LOG: B0Map shape after processing: {B0Mask.shape}")

              # Leaving for future debugging
              B0Mask_img = nib.Nifti1Image(B0Mask[:,:,0,0,:], affine=BrainMask_load.affine)
              outputfile = "/buildhostdirectory/tmp/niftis/B0Mask.nii"
              nib.save(B0Mask_img, outputfile)
              logging.info(f"CBS_LOG: Saved B0Mask to B0Mask.nii")
              if os.path.exists(outputfile):
                 logging.info("CBS_LOG: B0Mask.nii exists!")
              else:
                 logging.error("CBS_LOG: B0Mask.nii NOT found!")

              B0MapOut = [None] * B0Mask.shape[-1]
              logging.info("CBS_LOG: B0mapImageSeriesIndex is: %d",B0mapImageSeriesIndex)

              B0MaxValue = np.max(B0Mask[B0Mask !=0])
              B0MinValue = np.min(B0Mask[B0Mask != 0])
              B0mean = np.mean(B0Mask)
              B0meanNoZero = np.mean(B0Mask[B0Mask != 0])
              B0SD = np.std(B0Mask)
              B0SDNoZero = np.std(B0Mask[B0Mask != 0])
              logging.info(f"CBS_LOG: Min(!0): {B0MinValue}, Max: {B0MaxValue}")
              logging.info(f"CBS_LOG: Mean: {B0mean:.5f}, STD: {B0SD:.5f}")
              logging.info(f"CBS_LOG:(No Zero) Mean: {B0meanNoZero:.5f}, STD: {B0SDNoZero:.5f}")
              for iImg in range(B0Mask.shape[-1]):
                  B0MapOut[iImg] = ismrmrd.Image.from_array(B0Mask[...,iImg].transpose((3, 2, 0, 1)), transpose=False)
                  # Create a copy of the original fixed header and update the data_type

                  oldHeader = TE1["head"][iImg]
                  oldHeader.data_type = B0MapOut[iImg].data_type
                  oldHeader.image_series_index = B0mapImageSeriesIndex
                  # Increment series number when flag detected (i.e. follow ICE logic for splitting series)
                  if mrdhelper.get_meta_value(TE1["meta"][iImg], 'IceMiniHead') is not None:
                      if mrdhelper.extract_minihead_bool_param(base64.b64decode(TE1["meta"][iImg]['IceMiniHead']).decode('utf-8'), 'BIsSeriesEnd') is True:
                          currentSeries += 1

                  B0MapOut[iImg].setHead(oldHeader)

                  # Create a copy of the original ISMRMRD Meta attributes from TE1 and update where possible
                  tmpMeta = TE1["meta"][iImg]
                  tmpMeta['DataRole']                       = 'Image'
                  tmpMeta['ImageProcessingHistory']         = ['PYTHON', 'OpenRecon recipe: cbsb0stats']
                  tmpMeta['WindowCenter']                   = str(np.round(((B0MaxValue - B0MinValue)/2)))
                  tmpMeta['WindowWidth']                    = str((B0MaxValue))
                  tmpMeta['SequenceDescriptionAdditional']  = 'OpenRecon'
                  tmpMeta['Keep_image_geometry']            = 1
                  tmpMeta['ImageComments']                  = f"Mean: {B0meanNoZero:.4f}, STD: {B0SD:.4f}" # Change the image comments to mean and SD
                  if tmpMeta.get('ImageRowDir') is None:
                      tmpMeta['ImageRowDir'] = ["{:.18f}".format(oldHeader.read_dir[0]), "{:.18f}".format(oldHeader.read_dir[1]), "{:.18f}".format(oldHeader.read_dir[2])]

                  if tmpMeta.get('ImageColumnDir') is None:
                      tmpMeta['ImageColumnDir'] = ["{:.18f}".format(oldHeader.phase_dir[0]), "{:.18f}".format(oldHeader.phase_dir[1]), "{:.18f}".format(oldHeader.phase_dir[2])]

                  metaXml = tmpMeta.serialize()

                  B0MapOut[iImg].attribute_string = metaXml
              B0map_Dict.clear()
              return B0MapOut
          ### -----
          def process(connection, config, metadata):
              global CONFIG_IS_TESTING, CONFIG_BITSSTORED,CONFIG_RESCALEINTERCEPT,CONFIG_RESCALESLOPE,isB0CollectionComplete,isB0PhaseCollected,isB0TEsCollected
              # Continuously parse incoming data parsed from MRD messages
              currentSeries = 0
              imgGroup = []

              waveformGroup = []

              B0map_Dict = {} # data collecting array for B0mask process

              GPUEnvironmentLog()


              if not os.path.exists(debugFolder):
                  os.makedirs(debugFolder)
                  logging.debug("CBS_LOG: Created folder " + debugFolder + " for debug output files")

              logging.info("CBS_LOG: Config: %s", config)

              # Metadata should be MRD formatted header, but may be a string
              # if it failed conversion earlier
              try:
                  # logging info, from openreconexample.py
                  logging.info("CBS_LOG: Incoming dataset contains %d encodings", len(metadata.encoding))
                  logging.info("CBS_LOG: First encoding is of type '%s', with a matrix size of (%s x %s x %s) and a field of view of (%s x %s x %s)mm^3", 
                      metadata.encoding[0].trajectory, 
                      metadata.encoding[0].encodedSpace.matrixSize.x, 
                      metadata.encoding[0].encodedSpace.matrixSize.y, 
                      metadata.encoding[0].encodedSpace.matrixSize.z, 
                      metadata.encoding[0].encodedSpace.fieldOfView_mm.x, 
                      metadata.encoding[0].encodedSpace.fieldOfView_mm.y, 
                      metadata.encoding[0].encodedSpace.fieldOfView_mm.z)
                  explore(metadata)



              except:
                  logging.info("CBS_LOG: Improperly formatted metadata: \n%s", metadata)


              try:
                  for item in connection:
                      # ----------------------------------------------------------
                      # Raw k-space data messages
                      # ----------------------------------------------------------
                      if isinstance(item, ismrmrd.Acquisition):
                          logging.error("CBS_ERROR: Raw k-space data is not supported by this module.")

                      # ----------------------------------------------------------
                      # Image data messages
                      # ----------------------------------------------------------
                      elif isinstance(item, ismrmrd.Image):
                          logging.info(f"CBS_LOG: image type {item.image_type} recieved")
                          logging.info(f"CBS_LOG: image seriex index is {item.image_series_index}")
                          try:
                              logging.info(f"CBS_LOG: image comment - {ismrmrd.Meta.deserialize(item.attribute_string)['ImageComments']}")
                          except:
                              logging.info(f"CBS_LOG: image comment not found")

                          # if (not isB0CollectionComplete) and isB0PhaseCollected and isB0TEsCollected:
                          #     logging.info(f"CBS_LOG: All B0 Images collected, setting flag to True")
                          #     isB0CollectionComplete = True
                          #     if (B0map_Dict["phase"] is not None):
                          #         logging.info("CBS_LOG: Processing B0map...")
                          #         image = b0mapProcess(B0map_Dict, currentSeries)
                          #         connection.send_image(image)
                          #         logging.info("CBS_LOG: B0map image sent through connection!")
                          #     else:
                          #         logging.info(f"CBS_WARNING: B0map data incomplete. Keys: {list(B0map_Dict)}")
                          #         logging.info(f"CBS_WARNING: Unable to B0map.")
                          #         B0map_Dict.clear()

                          if (not isB0CollectionComplete) and ((not isB0PhaseCollected) or (not isB0TEsCollected)):
                              logging.info(f"CBS_LOG: Collecting image")
                          
                              if item.image_series_index != currentSeries:
                                  logging.info("CBS_LOG: Processing a group of images because series index changed to %d", item.image_series_index)
                                  currentSeries = item.image_series_index
                                  image = process_image(imgGroup, connection, config, metadata, B0map_Dict)
                                  logging.debug(f"CBS_DEBUG: isB0CollectionComplete: {isB0CollectionComplete}")
                                  connection.send_image(image)
                                  imgGroup = []

                              # Collect magnitude and phase images for processing
                              if (item.image_type is ismrmrd.IMTYPE_MAGNITUDE) or (item.image_type == 0) or (item.image_type is ismrmrd.IMTYPE_PHASE) or (item.image_type == 2):
                                  imgGroup.append(item)
                                  if (mrdhelper.get_json_config_param(config, 'sendoriginal', default=False, type='bool')):
                                      connection.send_image(item)
                                  

                          else:
                              tmpMeta = ismrmrd.Meta.deserialize(item.attribute_string)
                              tmpMeta['Keep_image_geometry']    = 1
                              item.attribute_string = tmpMeta.serialize()

                              connection.send_image(item)
                              continue

                      # ----------------------------------------------------------
                      # Waveform data messages
                      # ----------------------------------------------------------
                      elif isinstance(item, ismrmrd.Waveform):
                          waveformGroup.append(item)

                      elif item is None:
                          break

                      else:
                          logging.error("CBS_ERROR: Unsupported data type %s", type(item).__name__)

                  # Extract raw ECG waveform data. Basic sorting to make sure that data 
                  # is time-ordered, but no additional checking for missing data.
                  # ecgData has shape (5 x timepoints)

                  if len(waveformGroup) > 0:
                      waveformGroup.sort(key = lambda item: item.time_stamp)
                      ecgData = [item.data for item in waveformGroup if item.waveform_id == 0]
                      ecgData = np.concatenate(ecgData,1)

                  if len(imgGroup) > 0:
                      logging.info("CBS_LOG: Processing a group of images (untriggered)")
                      image = process_image(imgGroup, connection, config, metadata,B0map_Dict)
                      connection.send_image(image)
                      imgGroup = []

                  logging.debug(f"CBS_DEBUG: isB0CollectionComplete: {isB0CollectionComplete},  isB0PhaseCollected: {isB0PhaseCollected}, isB0TEsCollected: {isB0TEsCollected}")
                  if (not isB0CollectionComplete) and isB0PhaseCollected and isB0TEsCollected:
                      logging.info(f"CBS_LOG: All B0 Images collected, setting flag to True")
                      isB0CollectionComplete = True
                      logging.debug(f"CBS_DEBUG: isB0CollectionComplete: {isB0CollectionComplete},  isB0PhaseCollected: {isB0PhaseCollected}, isB0TEsCollected: {isB0TEsCollected}")
                      if (B0map_Dict["phase"] is not None):
                          logging.info("CBS_LOG: Processing B0map...")
                          image = b0mapProcess(B0map_Dict, currentSeries,config)
                          connection.send_image(image)
                          logging.info("CBS_LOG: B0map image sent through connection!")
                      else:
                          logging.info(f"CBS_WARNING: B0map data incomplete. Keys: {list(B0map_Dict)}")
                          logging.info(f"CBS_WARNING: Unable to B0map.")
                          B0map_Dict.clear()


              except Exception as e:
                  logging.error(traceback.format_exc())
                  connection.send_logging(constants.MRD_LOGGING_ERROR, traceback.format_exc())

              finally:
                  connection.send_close()

          def process_image(images, connection, config, metadata,B0map_Dict):
              global isB0TEsCollected,isB0PhaseCollected
              if len(images) == 0:
                  return []
              images = sorted(images, key=getInstanceNumber) # Sorts images by Instance Number
              logging.info(f"CBS_LOG: Images Instances is:")
              [logging.info(f"{int(getInstanceNumber(i))}") for i in images]
              if (images[0].image_type is ismrmrd.IMTYPE_MAGNITUDE) or (images[0].image_type == 1):
                  # Note: The MRD Image class stores data as [cha z y x]
                  # Extract image data into a 5D array of size [img cha z y x]
                  data = np.stack([img.data                              for img in images])
                  head = [img.getHead()                                  for img in images]
                  meta = [ismrmrd.Meta.deserialize(img.attribute_string) for img in images]
                  B0map_Dict[findTE(meta,metadata)] = images
                  if (len(B0map_Dict) == 2) and (B0map_Dict.get("phase") is None):
                      isB0TEsCollected = True
                  elif (len(B0map_Dict) == 3) and (B0map_Dict.get("phase") is not None):
                      isB0TEsCollected = True
                      
                  getDiagnosticInfo(images,data,head,meta,metadata,B0map_Dict)
                  
                  
                  
                  # Reformat data to [y x img cha z], i.e. [row ~col] for the first two dimensions from an initial [z char img x y]
                  data = data.transpose((3, 4, 2, 1, 0)).astype(np.float64)
                  if CONFIG_IS_TESTING:
                      data = data*CONFIG_RESCALESLOPE + CONFIG_RESCALEINTERCEPT
                  # rescaleIntercept = np.array([getAcquisitionData(m, "ri") for m in meta])
                  # rescaleSlope = np.array([getAcquisitionData(m, "rs") for m in meta])
                  #data = data*rescaleSlope - rescaleIntercept
                  logging.debug("CBS_DEBUG: Original image data after transposing is %s" % (data.shape,))
                  currentSeries = 0

                  imagesOut = imageOutPreparation_basic(data,head,meta,currentSeries)
                  return imagesOut
              elif (images[0].image_type is ismrmrd.IMTYPE_PHASE) or (images[0].image_type == 2):
                  #logging.debug("CBS_DEBUG: PHASE DETECTED")
                  # Note: The MRD Image class stores data as [cha z y x]
                  # Extract image data into a 5D array of size [img cha z y x]
                  data = np.stack([img.data                              for img in images])
                  head = [img.getHead()                                  for img in images]
                  meta = [ismrmrd.Meta.deserialize(img.attribute_string) for img in images]
                  B0map_Dict["phase"] = images
                  isB0PhaseCollected = True
                  
                  getDiagnosticInfo(images,data,head,meta,metadata,B0map_Dict)

                  # Reformat data to [y x img cha z], i.e. [row ~col] for the first two dimensions
                  data = data.transpose((3, 4, 2, 1, 0)).astype(np.float64)
                  if CONFIG_IS_TESTING:
                      data = data*CONFIG_RESCALESLOPE + CONFIG_RESCALEINTERCEPT
                  logging.debug("CBS_DEBUG: Original image data after transposing is %s" % (data.shape,))
                  currentSeries = 0

                  imagesOut = imageOutPreparation_basic(data,head,meta,currentSeries)
                  return imagesOut       
    - install: bzip2 ca-certificates git wget build-essential python3-pip python-is-python3
    - workdir: /opt/code
    - install:
        - build-essential
        - libxslt1.1
        - libboost-program-options1.74.0
        - libpugixml1v5
        - vim
        - dos2unix
        - git
        - cmake
        - g++
        - libhdf5-dev
        - libxml2-dev
        - libxslt1-dev
        - libboost-all-dev
        - libfftw3-dev
        - libpugixml-dev
    - run:
        - git clone https://github.com/ismrmrd/ismrmrd.git
        - cd ./ismrmrd
        - cmake .
        - make -j {{ parallel_jobs }}
        - make install
    - run:
        - git clone --branch  v1.2.13 https://github.com/ismrmrd/siemens_to_ismrmrd.git
        - cd siemens_to_ismrmrd
        - mkdir build
        - cd build
        - cmake ..
        - make -j {{ parallel_jobs }}
        - make install
    - run:
        - pip3 install h5py ismrmrd==1.14.1 matplotlib pydicom==3.0.1 pynetdicom nibabel scipy scikit-image
        - pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    - run:
        - git clone https://github.com/ismrmrd/ismrmrd-python-tools.git
        - cd ismrmrd-python-tools
        - pip3 install --no-cache-dir .
    - run:
        - git clone https://github.com/kspaceKelvin/python-ismrmrd-server
        - find /opt/code/python-ismrmrd-server -name "*.sh" -exec chmod +x {} \;
        - find /opt/code/python-ismrmrd-server -name "*.sh" | xargs dos2unix
        - sed -i 's/invertcontrast/default_replace_with_valid_name/g' /opt/code/python-ismrmrd-server/main.py
    - template:
        name: fsl
        version: 6.0.7.18
    - deploy:
        path:
          - /opt/code/FSL-BET2/bin
    - environment:
        DEBIAN_FRONTEND: noninteractive
    - install:
        - gcc-aarch64-linux-gnu cmake make build-essential
    - workdir: /opt/code
    - run:
        - git clone https://github.com/Bostrix/FSL-BET2
        - cd FSL-BET2
        - mkdir build
        - cd build
        - cmake ..
        - make
    - environment:
        PATH: /usr/bin:/opt/code/FSL-BET2/bin:$PATH
    - copy:
        - cbsb0stats.py
        - /opt/code/python-ismrmrd-server/cbsb0stats.py
categories:
  - functional imaging
